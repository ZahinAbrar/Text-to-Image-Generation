
# ğŸ§ª Diffusion API with FastAPI, Docker, and Kubernetes

![FastAPI](https://img.shields.io/badge/framework-FastAPI-green)
![Docker](https://img.shields.io/badge/container-Docker-blue)
![Kubernetes](https://img.shields.io/badge/deployment-Kubernetes-success)
![Transformers](https://img.shields.io/badge/model-HuggingFace-orange)
![License](https://img.shields.io/badge/license-MIT-lightgrey)

---

## ğŸ§  Overview

This project implements a **full-stack ML deployment pipeline** using a Stable Diffusion model. It demonstrates how to serve a generative model using **FastAPI**, containerize it with **Docker**, and scale it with **Kubernetes**.

The core endpoint `/generate` receives a text prompt like `"a futuristic robot reading a book under a tree"` and returns the generated image in PNG format.

---

## ğŸ”§ Tech Stack

- **Model**: Stable Diffusion v1-4 (via Hugging Face Transformers)
- **API Framework**: FastAPI
- **Containerization**: Docker
- **Orchestration**: Kubernetes
- **Serving**: Uvicorn server with autoscaling setup

---

## ğŸ“¦ Features

- ğŸŒ Exposes an endpoint `/generate` for real-time image generation
- ğŸ“¦ Fully containerized with a reproducible Dockerfile
- â˜ï¸ Cloud-ready and GPU-portable (GCP, AWS, Azure)
- ğŸ“ˆ Auto-scalable using Kubernetes HPA
- âš™ï¸ Easily replaceable with vLLM, DeepSpeed-MII, or other models

---

## ğŸ§ª API Endpoint

### POST `/generate`

**Input**:
```json
{
  "prompt": "a futuristic robot reading a book under a tree"
}
```

**Output**:
- PNG image stream in response

---

## ğŸš€ Run Locally with Docker

```bash
docker build -t diffusion-api .
docker run -p 8000:8000 diffusion-api
```

---

## â˜¸ï¸ Kubernetes Deployment

Includes the following components:
- `Deployment.yaml` (2 replicas for availability)
- `Service.yaml` (LoadBalancer for external access)
- `HPA.yaml` (auto-scales pods based on CPU usage)

```bash
kubectl apply -f k8s/
```

---

## ğŸ“‚ Project Structure

```
ğŸ“ diffusion-api/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py             # FastAPI app definition
â”œâ”€â”€ Dockerfile              # Docker build instructions
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â””â”€â”€ hpa.yaml
```

---

## ğŸ“Œ Note

Though designed and demoed in Google Colab, the project is fully portable and production-ready. Adapt to your own infrastructure or integrate with other generative models.

---

## ğŸ“ License

This project is released under the [MIT License](LICENSE).
